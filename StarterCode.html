<!DOCTYPE html>
<html>
<head>
<title>StarterCode.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="the-ar7-model">The AR(7) Model</h1>
<p>The AR(7) Model is defined as:
$$
y_t = c + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \phi_3 y_{t-3} + \phi_4 y_{t-4} + \phi_5 y_{t-5} + \phi_6 y_{t-6} + \phi_7 y_{t-7} + u_t
$$
where $u_t \sim N(0, \sigma^2)$.</p>
<p>We can then define the conditional likelihood function as:
$$
L(y,\phi) = f(y_1, y_2, y_3, y_4, y_5, y_6, y_7;\phi)\prod_{t=8}^Tf(y_t|y_{t-1},..., y_{t-7};\phi)
$$
The conditional log-likelihood function is:
$$
\ell (y; \phi) = \log( f(y_1,..., y_7;\phi))+\sum_{t=8}^T \log (f(y_t|y_{t-1},..., y_{t-7};\phi))
$$</p>
<p>We regard the first 7 observation or their joint distribution as a determenistic quality and thus:</p>
<p>$$
\ell (y; \phi) \propto \sum_{t=8}^T \log(f(y_t|y_{t-1},..., y_{t-7};\phi))
$$
Also, since the error terms are normally distributed with mean 0 and varieance $\sigma^2$, we can determine the conditional distribution of $y_t$ as:
$$
y_t|y_{t-1},y_{t-2}, ..., y_{t-7} \sim N(c + \phi_1y_{t-1} + ... + \phi_7 y_{t-7}, \sigma^2)
$$
Therefore, to implement the conditional log-likelihood function we can code it as the sum of normally distributed variables.
$$
\ell_C (y; \phi) \propto \sum_{t=8}^T \log \left( \frac{1}{\sigma \sqrt{2\pi}} \exp \left{-\frac{(y_t - (c+ \phi_1y_{t-1} + ... + \phi_7 y_{t-7} ))^2}{2\sigma^2} \right} \right)
$$</p>
<p>The unconditional likelihood function starts from a similar approach.
However, instead of regarding the first 7 observations as determenistic it regards them as multivariate normally distributed with mean $\mu$ and covariance $\Sigma$.
$$
\ell_U (y; \phi) = \log( f(y_1,..., y_7;\phi, \mu, \Sigma))+\sum_{t=8}^T \log (f(y_t|y_{t-1},..., y_{t-7};\phi))
$$
The second term on the right hand side is the conditional log-likelihood, the first term is the multivariate normal distribution of the first seven observations.</p>
<h1 id="mean-covariance">Mean, Covariance</h1>
<p>This code implements the equation
$$
\mu = (I - A)^{-1}b
$$
to compute the mean adn then implement the Lyapunov equation
$$
\Sigma = A \Sigma A^T + Q
$$
to compute the covariance matrix of the autoregressive process.</p>
<p>First, the matrix $A$ is constructed, which is a square matrix where the first row is made up of $\phi_1, \phi_2, ..., \phi_p$ of the autoregressive process of order $p$ and the other rows are in reduced row echelon form.</p>
<p>For this the command <strong>np.zeros((p,p))</strong> is used, which creates an array of dimension $p \times p$ filled with zeros.
Next, we replace the first row with $\phi_1, \phi_2, ..., \phi_p$ by subsetting $A$ with the command <strong>A[0, :] = phis</strong>.
Next, to fill the remaining rows except the last row with leading ones the comman np.eye is used.</p>
<p>Thus for given $p$ and vector $\phi$, this code creates the matrix A:</p>
<pre class="hljs"><code><div>    p = len(phis)
    A = np.zeros((p, p))
    A[<span class="hljs-number">0</span>, :] = phis
    A[<span class="hljs-number">1</span>:, <span class="hljs-number">0</span>:(p<span class="hljs-number">-1</span>)] = np.eye(p<span class="hljs-number">-1</span>)
</div></code></pre>
<p>Next, the vector $\vec{b}$ is constructed which is a vector with the constant $c$ in the first position and zeros elsewhere:</p>
<pre class="hljs"><code><div>    b = np.zeros((p, <span class="hljs-number">1</span>))
    b[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>] = c
</div></code></pre>
<p>Then the equation to find the mean is solved:</p>
<pre class="hljs"><code><div>    I = np.eye(p)
    mu = np.linalg.inv(I - A) @ b
</div></code></pre>
<p>Then, the matrix $Q$ of the Lyapunov equation is construced as a matrix with $\sigma^2$ on position [0,0] and zeros elsewhere.</p>
<pre class="hljs"><code><div>    Q = np.zeros((p,p))
    Q[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>] = sigma2
</div></code></pre>
<p>Lastly the Lyapunov equation in solved:</p>
<pre class="hljs"><code><div>Sigma = scipy.linalg.solve_discrete_lyapunov(A, Q)
</div></code></pre>
<p>The entire code is below. <strong>ravel()</strong> is a function that flattens a multideimensional array into one dimension.</p>
<pre class="hljs"><code><div><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> scipy 

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">unconditional_ar_mean_variance</span><span class="hljs-params">(c, phis, sigma2)</span>:</span>
    <span class="hljs-comment">## The length of phis is p</span>
    p = len(phis)
    A = np.zeros((p, p))
    A[<span class="hljs-number">0</span>, :] = phis
    A[<span class="hljs-number">1</span>:, <span class="hljs-number">0</span>:(p<span class="hljs-number">-1</span>)] = np.eye(p<span class="hljs-number">-1</span>)
    <span class="hljs-comment">## Check for stationarity</span>
    eigA = np.linalg.eig(A)
    <span class="hljs-keyword">if</span> all(np.abs(eigA.eigenvalues)&lt;<span class="hljs-number">1</span>):
        stationary = <span class="hljs-literal">True</span>
    <span class="hljs-keyword">else</span>:
        stationary = <span class="hljs-literal">False</span>
    <span class="hljs-comment"># Create the vector b</span>
    b = np.zeros((p, <span class="hljs-number">1</span>))
    b[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>] = c
    
    <span class="hljs-comment"># Compute the mean using matrix algebra</span>
    I = np.eye(p)
    mu = np.linalg.inv(I - A) @ b
    
    <span class="hljs-comment"># Solve the discrete Lyapunov equation</span>
    Q = np.zeros((p, p))
    Q[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>] = sigma2
    <span class="hljs-comment">#Sigma = np.linalg.solve(I - np.kron(A, A), Q.flatten()).reshape(7, 7)</span>
    Sigma = scipy.linalg.solve_discrete_lyapunov(A, Q)
    
    <span class="hljs-keyword">return</span> mu.ravel(), Sigma, stationary

<span class="hljs-comment"># Example usage:</span>
phis = [<span class="hljs-number">0.2</span>, <span class="hljs-number">-0.1</span>, <span class="hljs-number">0.05</span>, <span class="hljs-number">-0.05</span>, <span class="hljs-number">0.02</span>, <span class="hljs-number">-0.02</span>, <span class="hljs-number">0.01</span>]
c = <span class="hljs-number">0</span>
sigma2 = <span class="hljs-number">0.5</span>
mu, Sigma, stationary = unconditional_ar_mean_variance(c, phis, sigma2)
print(<span class="hljs-string">"The process is stationary:"</span>, stationary)
print(<span class="hljs-string">"Mean vector (mu):"</span>, mu)
print(<span class="hljs-string">"Variance-covariance matrix (Sigma);"</span>, Sigma)
</div></code></pre>
<h1 id="conditional-and-unconditional-likelihood-functions">Conditional and Unconditional Likelihood Functions</h1>
<p>The parameters of the model are the constant $c$, the coefficients $\phi_1, ..., \phi_7$ and the variance of the normally distributed error terms $\sigma^2$.
They are passed to the function as a single list of parameters $\text{params} = (c; \phi_1, ..., \phi_7; \sigma^2)$.</p>
<pre class="hljs"><code><div>c = params[<span class="hljs-number">0</span>] 
    phi = params[<span class="hljs-number">1</span>:<span class="hljs-number">8</span>]
    sigma2 = params[<span class="hljs-number">8</span>]
</div></code></pre>
<p>The function defined above is used to retrieve the Covariance Matrix, the mean and to check whether the process is stationary:</p>
<pre class="hljs"><code><div>mu, Sigma, stationary = unconditional_ar_mean_variance(c, phi, sigma2)
</div></code></pre>
<p>As described above, the conditional log-likelihood function is a sum of normally distributed variables, specifically the conditional distribution is $ N(c + \phi_1y_{t-1} + ... + \phi_7 y_{t-7}, \sigma^2)$.</p>
<pre class="hljs"><code><div>loglik = np.sum(norm.logpdf(yf, loc=(c + Xf@phi), scale=np.sqrt(sigma2)))
</div></code></pre>
<p>The unconditional log-likelihood as stated above is the conditional log-likelihood plus the multivariate distribution of the first seven observations.
In the code the parameters of the multivariate normal distribution are derived via the equation $\mu = (I-A)^{-1}b$ and the Lyapunov equation.</p>
<pre class="hljs"><code><div>    mu, Sigma, stationary = unconditional_ar_mean_variance(c, phi, sigma2)

</div></code></pre>
<p>Then the multivariate normal distribution is implemented:</p>
<pre class="hljs"><code><div>    mvn = multivariate_normal(mean=mu, cov=Sigma, allow_singular=<span class="hljs-literal">True</span>)
    uloglik = cloglik + mvn.logpdf(y[<span class="hljs-number">0</span>:<span class="hljs-number">7</span>])
</div></code></pre>
<p>Thus, the unconditional log-likelihood is coded as:</p>
<pre class="hljs"><code><div>    uloglik = cloglik + mvn.logpdf(y[<span class="hljs-number">0</span>:<span class="hljs-number">7</span>])
</div></code></pre>
<p>The entire code chunk is:</p>
<pre class="hljs"><code><div><span class="hljs-keyword">from</span> scipy.stats <span class="hljs-keyword">import</span> norm
<span class="hljs-keyword">from</span> scipy.stats <span class="hljs-keyword">import</span> multivariate_normal
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lagged_matrix</span><span class="hljs-params">(Y, max_lag=<span class="hljs-number">7</span>)</span>:</span>
    n = len(Y)
    lagged_matrix = np.full((n, max_lag), np.nan)    
    <span class="hljs-comment"># Fill each column with the appropriately lagged data</span>
    <span class="hljs-keyword">for</span> lag <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, max_lag + <span class="hljs-number">1</span>):
        lagged_matrix[lag:, lag - <span class="hljs-number">1</span>] = Y[:-lag]
    <span class="hljs-keyword">return</span> lagged_matrix


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">cond_loglikelihood_ar7</span><span class="hljs-params">(params, y)</span>:</span>
    c = params[<span class="hljs-number">0</span>] 
    phi = params[<span class="hljs-number">1</span>:<span class="hljs-number">8</span>]
    sigma2 = params[<span class="hljs-number">8</span>]
    mu, Sigma, stationary = unconditional_ar_mean_variance(c, phi, sigma2)
    <span class="hljs-comment">## We could check that at phis the process is stationary and return -Inf if it is not</span>
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span>(stationary):
        <span class="hljs-keyword">return</span> -np.inf
    <span class="hljs-comment">## The distribution of </span>
    <span class="hljs-comment"># y_t|y_{t-1}, ..., y_{t-7} ~ N(c+\phi_{1}*y_{t-1}+...+\phi_{7}y_{t-7}, sigma2)</span>
    <span class="hljs-comment">## Create lagged matrix</span>
    X = lagged_matrix(y, <span class="hljs-number">7</span>)
    yf = y[<span class="hljs-number">7</span>:]
    Xf = X[<span class="hljs-number">7</span>:,:]
    loglik = np.sum(norm.logpdf(yf, loc=(c + Xf@phi), scale=np.sqrt(sigma2)))
    <span class="hljs-keyword">return</span> loglik

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">uncond_loglikelihood_ar7</span><span class="hljs-params">(params, y)</span>:</span>
    <span class="hljs-comment">## The unconditional loglikelihood</span>
    <span class="hljs-comment">## is the unconditional "plus" the density of the</span>
    <span class="hljs-comment">## first p (7 in our case) observations</span>
    cloglik = cond_loglikelihood_ar7(params, y)

    <span class="hljs-comment">## Calculate initial</span>
    <span class="hljs-comment"># y_1, ..., y_7 ~ N(mu, sigma_y)</span>
    c = params[<span class="hljs-number">0</span>] 
    phi = params[<span class="hljs-number">1</span>:<span class="hljs-number">8</span>]
    sigma2 = params[<span class="hljs-number">8</span>]
    mu, Sigma, stationary = unconditional_ar_mean_variance(c, phi, sigma2)
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span>(stationary):
        <span class="hljs-keyword">return</span> -np.inf
    mvn = multivariate_normal(mean=mu, cov=Sigma, allow_singular=<span class="hljs-literal">True</span>)
    uloglik = cloglik + mvn.logpdf(y[<span class="hljs-number">0</span>:<span class="hljs-number">7</span>])
    <span class="hljs-keyword">return</span> uloglik
    

<span class="hljs-comment">## Example</span>
params = np.array([
    <span class="hljs-number">0.0</span>, <span class="hljs-comment">## c</span>
    <span class="hljs-number">0.2</span>, <span class="hljs-number">-0.1</span>, <span class="hljs-number">0.05</span>, <span class="hljs-number">-0.05</span>, <span class="hljs-number">0.02</span>, <span class="hljs-number">-0.02</span>, <span class="hljs-number">0.01</span>, <span class="hljs-comment">## phi</span>
    <span class="hljs-number">1.0</span> <span class="hljs-comment">## sigma2    </span>
    ])

<span class="hljs-comment">## Fake data</span>
y = np.random.normal(size=<span class="hljs-number">100</span>)

<span class="hljs-comment">## The conditional distribution</span>
cond_loglikelihood_ar7(params, y)
<span class="hljs-comment">## The unconditional distribution</span>
uncond_loglikelihood_ar7(params, y)
</div></code></pre>
<h1 id="maximum-likelihood-with-simulated-data">Maximum Likelihood with Simulated Data</h1>
<pre class="hljs"><code><div><span class="hljs-comment">## Unconditional - define the negative loglikelihood</span>

<span class="hljs-comment">## Starting value. </span>
<span class="hljs-comment">## These estimates should be close to the OLS</span>
X = lagged_matrix(y, <span class="hljs-number">7</span>)
yf = y[<span class="hljs-number">7</span>:]
Xf = np.hstack((np.ones((<span class="hljs-number">93</span>,<span class="hljs-number">1</span>)), X[<span class="hljs-number">7</span>:,:]))
beta = np.linalg.solve(Xf.T@Xf, Xf.T@yf)
sigma2_hat = np.mean((yf - Xf@beta)**<span class="hljs-number">2</span>)

params = np.hstack((beta, sigma2_hat))

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">cobj</span><span class="hljs-params">(params, y)</span>:</span> 
    <span class="hljs-keyword">return</span> - cond_loglikelihood_ar7(params,y)

results = scipy.optimize.minimize(cobj, params, args = y, method=<span class="hljs-string">'L-BFGS-B'</span>)

<span class="hljs-comment">## If everything is correct, results.x should be equal to the OLS parameters.</span>

<span class="hljs-comment">## Not the conditional</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">uobj</span><span class="hljs-params">(params, y)</span>:</span> 
    <span class="hljs-keyword">return</span> - uncond_loglikelihood_ar7(params,y)

bounds_constant = tuple((-np.inf, np.inf) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>))
bounds_phi = tuple((<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(<span class="hljs-number">7</span>))
bounds_sigma = tuple((<span class="hljs-number">0</span>,np.inf) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>))
bounds = bounds_constant + bounds_phi + bounds_sigma

<span class="hljs-comment">## L-BFGS-B support bounds</span>
results = scipy.optimize.minimize(uobj, results.x, args = y, method=<span class="hljs-string">'L-BFGS-B'</span>, bounds = bounds)
</div></code></pre>
<h1 id="next-steps">Next Steps</h1>
<p>Next, we need to actually estimate the parameters with MLE using the <span style="color:purple">INDPRO</span> variable from the FREDMD dataset.</p>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
</body>
</html>
